w23=(0.01478172+0.01466109)/(0.06133939+0.06083882)
w13
w23
incid_beta1
w1
mort_beta1
w2
df_with_w
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
log_RR
#create the logrisk ratios for each timepoint
results_df=data.frame()
results_df
cbind(results_df,log_RR,exp(log_RR))
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
results_df=data.frame(cbind(log_RR,exp(log_RR)))
results_df
incid_stderr1
mort_stderr1
var_logRR <- (df_with_w$w1^2)*(incid_stderr1^2) + (df_with_w$w2^2)*(mort_stderr1^2)
var_logRR
results_df=cbind(results_df,var_logRR)
results_df$lcl_logRR <- results_df$log_RR - 1.96 * sqrt(results_df$var_logRR)
results_df$ucl_logRR <- results_df$log_RR + 1.96 * sqrt(results_df$var_logRR)
results_df
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
results_df=data.frame(cbind(log_RR))
var_logRR <- (df_with_w$w1^2)*(incid_stderr1^2) + (df_with_w$w2^2)*(mort_stderr1^2)
results_df=cbind(results_df,var_logRR)
# Confidence intervals
se_logRR  <- sqrt(var_logRR)
results_df$lcl_logRR <- results_df$log_RR - 1.96 * sqrt(results_df$var_logRR)
results_df$ucl_logRR <- results_df$log_RR + 1.96 * sqrt(results_df$var_logRR)
results_df
# Exponentiated version (RR scale)
RR       <- exp(log_RR)
RR_lower <- exp(lcl_logRR)
RR_upper <- exp(ucl_logRR)
# Exponentiated version (RR scale)
results_df$RR       <- exp(results_df$log_RR)
results_df$RR_lower <- exp(results_df$lcl_logRR)
results_df$RR_upper <- exp(results_df$ucl_logRR)
results_df
# p-value
z_score  <- log_RR / se_logRR
p_val    <- 2 * (1 - pnorm(abs(z_score)))
list(
w1 = w1,
w2 = w2,
log_RR = log_RR,
RR     = RR,
CI     = c(RR_lower, RR_upper),
pvalue = p_val
)
results_df
# p-value
results_df$z_score  <- results_df$log_RR / results_df$se_logRR
results_df$se_logRR
sqrt(results_df$var_logRR)
# p-value
results_df$z_score  <- results_df$log_RR / sqrt(results_df$var_logRR)
results_df$p_val    <- 2 * (1 - pnorm(abs(results_df$z_score)))
results_df
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol<-read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Datafracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
response <- "foc_01"
poww1 <- "minushalf"
poww2 <- "plushalf"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='uni_01', age_var='age', gender_var='Sex', id_var="id")
# Display the plots
ggarrange(plots$spaghetti_plot,plots$loess_plot,ncol=2)
plots$loess_plot
plots
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
library(xtable)
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
response <- "uni_01"
poww1 <- "minus2"
poww2 <- "plus1"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='uni_01', age_var='age', gender_var='Sex', id_var="id")
plots
plots
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
fracpol$log_plushalf=fracpol$log*fracpol$plushalf
response <- "gen_01"
poww1 <- "plushalf"
poww2 <- "log_plushalf"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
#initial_model=final_model
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='gen_01', age_var='age', gender_var='Sex', id_var="id")
plots$loess_plot
# Display the plots
ggarrange(plots$spaghetti_plot,plots$loess_plot,ncol=2)
plots
4563/365
3650/365
1825/365
8/1.6
96/5
64/3.5
i=1
0.05/(5-i+1)
i=2
0.05/(5-i+1)
i=3
0.05/(5-i+1)
i=4
0.05/(5-i+1)
i=5
0.05/(5-i+1)
i=5
0.05/(5-i+1)
i=1
0.05/(5-i+1)
90-(18.25+19.35+28.25)
param_grid <- expand.grid(
learning_rate = c(0.01, 0.05, 0.1),
max_depth = c(3, 5, 7),
num_leaves = c(15, 31, 63),  # must be < 2^max_depth
lambda_l1 = c(0, 1, 5),
lambda_l2 = c(0, 1, 5),
min_data_in_leaf = c(10, 20, 50),
feature_fraction = c(0.6, 0.8, 1.0),
bagging_fraction = c(0.6, 0.8, 1.0),
bagging_freq = c(1)  # how often to apply bagging
)
param_grid
nrow(param_grid)
### High dimension linear model
rm(list = ls())
#mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleLassoHD.R'))
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(neuralnet)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
### algorithmic settings
num_split <- 1
n <-1500
p <- 2000
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
#######set up the method for the comparison############# i=10
Compare_SignalStrength <- function(i, s) {
set.seed(s)
delta <- i
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- scale(X %*% beta_star + rnorm(n))
# run your custom methods
g1 <- ApplyTriangleLassoHD(X = X, y = y, q = q, num_split = num_split,
signal_index = signal_index, myseed = 1)
# FDR methods
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- knockoff(    X = X, y = y, q = q)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Boost DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Boost MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power),
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
return(ResultsDataFrame)
}
##check how long one iteration takes
system.time({
Compare_SignalStrength(7,7)
# Replace this block with the code you want to time
Sys.sleep(1)  # This just waits for 1 second
})
num_split <- 2
n <-1500
p <- 2000
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
#######set up the method for the comparison############# i=10
Compare_SignalStrength <- function(i, s) {
set.seed(s)
delta <- i
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- scale(X %*% beta_star + rnorm(n))
# run your custom methods
g1 <- ApplyTriangleLassoHD(X = X, y = y, q = q, num_split = num_split,
signal_index = signal_index, myseed = 1)
# FDR methods
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- knockoff(    X = X, y = y, q = q)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Boost DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Boost MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power),
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
return(ResultsDataFrame)
}
##check how long one iteration takes
system.time({
Compare_SignalStrength(7,7)
# Replace this block with the code you want to time
Sys.sleep(1)  # This just waits for 1 second
})
Compare_SignalStrength(7,7)
### High dimension linear model
rm(list = ls())
#mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleLassoHD.R'))
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(neuralnet)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
### algorithmic settings
num_split <- 2
n <-1500
p <- 2000
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
#######set up the method for the comparison############# i=10
Compare_SignalStrength <- function(i, s) {
set.seed(s)
delta <- i
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))
y <- scale(X %*% beta_star + rnorm(n))
# run your custom methods
g1 <- ApplyTriangleLassoHD(X = X, y = y, q = q, num_split = num_split,
signal_index = signal_index, myseed = 1)
# FDR methods
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- knockoff(    X = X, y = y, q = q)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Boost DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Boost MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power),
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
return(ResultsDataFrame)
}
Compare_SignalStrength(7,7)
