num_split   <- 5#0#5010   # Number of data splits
q=0.1
# Setup Parallel Backend
#X=mydata[,-c(1,4,8,9,12,13,16,17,18,19)]
p <- ncol(X)   # number of OTUs
n_cores <- max(1, parallel::detectCores(logical = TRUE) - 1)
cl <- parallel::makeCluster(n_cores)
cl
registerDoParallel(cl)
registerDoRNG(11272025) # Set seed for reproducibility
set.seed(1272025)
# ==============================================================================
# 5. Main Parallel Loop (Data Splitting)
# ==============================================================================
mydata_full=as.data.frame(cbind(y,X))
res_mat <- foreach(iter = 1:num_split,
.combine = "rbind",
.packages = c("randomForest")) %dorng% {
permR2 <- function(data, Y, j, model) {
Xperm <- data
# Permute column j
Xperm[, j] <- sample(data[, j], replace = FALSE)
# Predict using permuted data
pred_perm <- predict(model, newdata = as.data.frame(Xperm))
# Calculate R2
rsq_perm <- 1 - sum((Y - pred_perm)^2) / sum((Y - mean(Y))^2)
return(rsq_perm)
}
source(paste0('C:/Users/mde4023/Downloads/FDR_Datasplitting','/Functions/HelperFunctions.R'))
p=1042;n=130
data_full=mydata_full
X=mydata_full[,-1]
y=mydata_full[,1]
# --- indices ---
train_index     <- sample.int(n, size = floor(amountTrain * n), replace = FALSE)
remaining_index <- setdiff(seq_len(n), train_index)
# split the remaining part in two halves
size_half     <- floor((amountTest / 2) * n)
sample_index1 <- sample(remaining_index, size = size_half, replace = FALSE)
sample_index2 <- setdiff(remaining_index, sample_index1)
dataTrain <- data_full[train_index, , drop = FALSE]
# --- fit RF using parameter vector pm ---350 260 16
mynlm <- randomForest(
y ~ .,
ntry=260,
ntree=350,
nodesize=16,
data    = dataTrain
)
# --- R² on the two halves ---
pred1 <- predict(mynlm, newdata = as.data.frame(X[sample_index1, , drop = FALSE]))
pred2 <- predict(mynlm, newdata = as.data.frame(X[sample_index2, , drop = FALSE]))
y1 <- y[sample_index1]
y2 <- y[sample_index2]
R2orig1 <- 1 - sum((y1 - pred1)^2) / sum((y1 - mean(y1))^2)
R2orig2 <- 1 - sum((y2 - pred2)^2) / sum((y2 - mean(y2))^2)
# --- permutation-based drops ---
Rnew1 <- sapply(seq_len(p), function(j)
permR2(as.data.frame(X[sample_index1, , drop = FALSE]), Y = y1, j = j, model = mynlm))
Rnew2 <- sapply(seq_len(p), function(j)
permR2(as.data.frame(X[sample_index2, , drop = FALSE]), Y = y2, j = j, model = mynlm))
beta1  <- R2orig1 - Rnew1
beta2  <- R2orig2 - Rnew2
mirror <- sign(beta1 * beta2) * (abs(beta1) + abs(beta2))
hist(mirror)
selected_index <- SelectFeatures(mirror, abs(mirror), q = 0.10)
num_sel <- length(selected_index)
inc_row <- numeric(p)
if (num_sel > 0) {
inc_row[selected_index] <- 1 / num_sel
}
c(num_sel, R2orig1, R2orig2, inc_row)
}
# ---- unpack ----
num_select     <- res_mat[, 1]
R2orig1_vec    <- res_mat[, 2]
R2orig2_vec    <- res_mat[, 3]
inclusion_rate_mat <- res_mat[, -(1:3), drop = FALSE]  # num_split x p
# MDS inclusion rates (avg across splits)
inclusion_rate <- apply(inclusion_rate_mat, 2, mean)
# Rank features by empirical inclusion rate
feature_rank <- order(inclusion_rate)
feature_rank <- setdiff(feature_rank, which(inclusion_rate == 0))
if (length(feature_rank) != 0) {
null_feature <- numeric()
for (feature_index in seq_along(feature_rank)) {
if (sum(inclusion_rate[feature_rank[1:feature_index]]) > q) break
null_feature <- c(null_feature, feature_rank[feature_index])
}
selected_index <- setdiff(feature_rank, null_feature)
}
selected_index
selected_index
mean(R2orig1_vec)
mean(R2orig2_vec)
exp(5.27)
exp(2.233)
exp(1.66)
exp(1.6618)
exp(0.027080)
exp(1.0978)
log(6.12)
exp(6.12)
6.12
exp(0.57)
library(readr)
library(doParallel)
library(doRNG)      # Reproducible parallel random numbers
library(microbiome)
library(earth)
library(dplyr)
library(earth)        # MARS
library(foreach)
library(doParallel)
library(ranger)
library(randomForest)
source(paste0('C:/Users/mde4023/Downloads/FDR_Datasplitting','/Functions/HelperFunctions.R'))
# Function to calculate Permuted R2 for a specific feature j
permR2 <- function(data, Y, j, model) {
Xperm <- data
# Permute column j
Xperm[, j] <- sample(data[, j], replace = FALSE)
# Predict using permuted data
pred_perm <- predict(model, newdata = as.data.frame(Xperm))
# Calculate R2
rsq_perm <- 1 - sum((Y - pred_perm)^2) / sum((Y - mean(Y))^2)
return(rsq_perm)
}
base_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Case study/qin2014"
task <- read_delim(file.path(base_dir, "mapping-orig.txt"),
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
otu <- read_delim(
file         = file.path(base_dir, "otutable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
taxa <- read_delim(
file         = file.path(base_dir, "taxatable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
taxa
base_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Case study/qin2014"
task <- read_delim(file.path(base_dir, "mapping-orig.txt"),
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
names(task)[1]='SampleID'
otu <- read_delim(
file         = file.path(base_dir, "otutable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
taxa <- read_delim(
file         = file.path(base_dir, "taxatable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
taxa
# Samples as rows, OTUs as columns
otu_t <- t(as.matrix(otu[, -1]))   # drop OTU ID column, transpose
namess=as.vector(otu[,1])
# Prevalence per OTU
prev <- colSums(otu_t > 0) / nrow(otu_t)
# Relative abundances
otu_rel <- otu_t / rowSums(otu_t)
# Filtering thresholds
min_prev        <- 0.10   # present in ≥10% of samples
min_relab       <- 1e-4   # minimum relative abundance
min_relab_prev  <- 0.05   # abundance > min_relab in ≥5% of samples
keep_prev  <- prev >= min_prev
keep_abund <- colSums(otu_rel > min_relab) / nrow(otu_rel) >= min_relab_prev
keep       <- keep_prev & keep_abund
otu_filtered <- otu_t[, keep, drop = FALSE]
ncol(otu_filtered)
ncol(otu_t)
namess_filtered=unlist(namess)[which(keep)]
namess_filtered
ncol(otu_t)
ncol(otu_filtered)
taxa <- read_delim(
file         = file.path(base_dir, "taxatable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
otu
taxa <- read_delim(
file         = file.path(base_dir, "taxatable.txt"),
delim        = "\t",
escape_double = FALSE,
trim_ws       = TRUE
)
taxa
View(taxa)
# Samples as rows, OTUs as columns
otu_t <- t(as.matrix(otu[, -1]))   # drop OTU ID column, transpose
namess=as.vector(otu[,1])
namess=as.vector(otu[,1])
namess
namess
namess=as.vector(otu[,1])
namess
task
table(task$Cirrhotic)
otu
taxa
otu
namess=as.vector(otu[,1])
namess
otu_t
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4/MarsParallelHD.R')
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4/Temp2"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
csv_files
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleBoosterTrainMS.R'))
source(paste0(mywd,'/Functions/ApplyGBMKnockoff.R'))
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4/MarsParallelHD.R')
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
#algorithmic settings
num_split <- 50
n <-500
p <- 550
p0 <- 10
q <- 0.10
amountTest=0.5
amountTrain=0.5
set.seed(11212025)
signal_index <- sample(c(1:p), size = p0, replace = F)
###choose the parameters
params =list(
objective = "reg:squarederror",
eta       = 0.005,
max_depth = 6,
lambda    = 0,
alpha     = 0
)
#######set up the method for the comparison############# i=7;s=1 num_split=1
Compare_SignalStrength <- function(i, s,other=T) {
set.seed(s)
delta <- i
# simulate data
n1 <- floor(n/2); n2 <- n - n1
X1 <- matrix(rnorm(n1*p, mean= 1), n1, p)
X2 <- matrix(rnorm(n2*p, mean=-1), n2, p)
X  <- rbind(X1, X2)
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- (X^2 %*% beta_star+ rnorm(n))
# run your custom methods
g1 <- ApplyMarsTrain_HDparallel( X = X, y = y, q = q, num_split = num_split,signal_index = signal_index, myseed = 1)
# FDR methods
if(other){
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- ApplyGBMKnockoff(    X = X, y = y, q = q,param=params)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
}
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Mars DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Mars MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power))
if(other){
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
}
return(ResultsDataFrame)
}
Compare_SignalStrength(7,1,F)
num_split <- 5
set.seed(s)
#######set up the method for the comparison############# i=7;s=1 num_split=1
Compare_SignalStrength <- function(i, s,other=T) {
set.seed(s)
delta <- i
# simulate data
n1 <- floor(n/2); n2 <- n - n1
X1 <- matrix(rnorm(n1*p, mean= 1), n1, p)
X2 <- matrix(rnorm(n2*p, mean=-1), n2, p)
X  <- rbind(X1, X2)
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- (X^2 %*% beta_star+ rnorm(n))
# run your custom methods
g1 <- ApplyMarsTrain_HDparallel( X = X, y = y, q = q, num_split = num_split,signal_index = signal_index, myseed = 1)
# FDR methods
if(other){
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- ApplyGBMKnockoff(    X = X, y = y, q = q,param=params)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
}
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Mars DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Mars MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power))
if(other){
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
}
return(ResultsDataFrame)
}
Compare_SignalStrength(7,1,F)
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleBoosterTrainMS.R'))
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/ApplyGBMKnockoff.R'))
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4/MarsParallelHD.R')
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
#algorithmic settings
num_split <- 50
n <-500
p <- 550
p0 <- 10
q <- 0.10
amountTest=0.5
amountTrain=0.5
set.seed(11212025)
signal_index <- sample(c(1:p), size = p0, replace = F)
###choose the parameters
params =list(
objective = "reg:squarederror",
eta       = 0.005,
max_depth = 6,
lambda    = 0,
alpha     = 0
)
#######set up the method for the comparison############# i=7;s=1 num_split=1
Compare_SignalStrength <- function(i, s,other=T) {
set.seed(s)
delta <- i
# simulate data
n1 <- floor(n/2); n2 <- n - n1
X1 <- matrix(rnorm(n1*p, mean= 1), n1, p)
X2 <- matrix(rnorm(n2*p, mean=-1), n2, p)
X  <- rbind(X1, X2)
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- (X^2 %*% beta_star+ rnorm(n))
# run your custom methods
g1 <- ApplyMarsTrain_HDparallel( X = X, y = y, q = q, num_split = num_split,signal_index = signal_index, myseed = 1)
# FDR methods
if(other){
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- ApplyGBMKnockoff(    X = X, y = y, q = q,param=params)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
}
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Mars DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Mars MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power))
if(other){
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
}
return(ResultsDataFrame)
}
#Compare_SignalStrength(7,1,F)
# build grid
param_grid <- expand.grid(
s = 1:200,
i = 7:13
)
# make sure output dir exists
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4'
out_dir <- file.path(mywd, "Temp2")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
# iterate over ROWS, not columns
for (k in seq_len(nrow(param_grid))) {
s_val <- param_grid$s[k]
i_val <- param_grid$i[k]
# compute chunk (wrap in tryCatch to avoid breaking the whole run)
chunk <- tryCatch(
Compare_SignalStrength(i = i_val, s = s_val),
error = function(e) {
message(sprintf("Failed at s=%s, i=%s: %s", s_val, i_val, conditionMessage(e)))
return(NULL)
}
)
if (is.null(chunk)) next
if (!is.data.frame(chunk)) chunk <- as.data.frame(chunk)
# write out this chunk immediately
fname <- sprintf("Results_s%02d_i%02d.csv", s_val, i_val)
write.csv(chunk, file = file.path(out_dir, fname), row.names = FALSE)
}
library(dplyr)
library(openxlsx)
library(ggplot2)
library(ggpubr)
library(readr)
# Path to your folder
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting/Scenario/Scenario4'
csv_dir=paste0(mywd,'/Temp2')
setwd("mywd")
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
Results=all_data
#visualise the results###########
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power),
N=length(FDR)
)
resultsagg$Signal_noisy <- as.numeric(resultsagg$SignalStrength) + runif(nrow(resultsagg), -0.2, 0.2)
resultsagg
