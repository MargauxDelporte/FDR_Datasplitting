library(MASS)
permR2TriangleLinRegTrain<-function(data,j,model){
dataPerm<-data[,-1]
dataPerm[,j]<-sample(data[,j+1],replace=FALSE)
predictLM<-predict(model,newdata=dataPerm)
rsquared=1-sum((data$y-predictLM)^2)/sum((data$y-mean(data$y))^2)
return(rsquared)
}
ApplyTriangleLinRegTrain<-function(X, y, q,amountTrain=0.333,amountTest=1-amountTrain,myseed,num_split=1,signal_index=signal_index){
set.seed(myseed)
n <- dim(X)[1]; p <- dim(X)[2]
inclusion_rate <- matrix(0, nrow = num_split, ncol = p)
fdp <- rep(0, num_split)
power <- rep(0, num_split)
num_select <- rep(0, num_split)
data<-data.frame(cbind(y,X))
for(iter in 1:num_split){
train_index<-sample(x = c(1:n), size = amountTrain * n, replace = F)
dataTrain<-data[train_index,]
colnames(dataTrain)<-c('y',paste0('X',1:p))
colnames(data)<-c('y',paste0('X',1:p))
lm<-lm(y~ ., data = dataTrain)
remaining_percent=1-amountTrain
overlap=max(c(0,amountTest-remaining_percent))
remaining_index<-c(setdiff(c(1:n),train_index),sample(train_index,size=overlap*n))
sample_index1 <- sample(x = remaining_index, size = amountTest/2 * n, replace = F)
sample_index2 <- setdiff(remaining_index, sample_index1)
predictLM1<-predict(lm,newdata=data.frame(data[sample_index1,]))
predictLM2<-predict(lm,newdata=data.frame(data[sample_index2,]))
R2orig1<-1-sum((y[sample_index1]-predictLM1)^2)/sum((y[sample_index1]-mean(y[sample_index1]))^2)
R2orig2<-1-sum((y[sample_index2]-predictLM2)^2)/sum((y[sample_index2]-mean(y[sample_index2]))^2)
Rnew1<-sapply(1:ncol(X),function(j) permR2TriangleLinRegTrain(data[sample_index1,],j,lm))
Rnew2<-sapply(1:ncol(X),function(j) permR2TriangleLinRegTrain(data[sample_index2,],j,lm))
Diff1=R2orig1-Rnew1
Diff2=R2orig2-Rnew2
sd_X1 <- apply(X[sample_index1, ], 2, sd)
sd_X2 <- apply(X[sample_index2, ], 2, sd)
beta1=sign(Diff1)*sqrt(abs(Diff1))*sd(y[sample_index1])/sd_X1
beta2=sign(Diff2)*sqrt(abs(Diff2))*sd(y[sample_index2])/sd_X2
mirror<-sign(beta1*beta2)*(abs(beta1))
selected_index<-SelectFeatures(mirror,abs(mirror),0.1)
### number of selected variables j=1
if(length(selected_index)!=0){
num_select[iter] <- length(selected_index)
inclusion_rate[iter, selected_index] <- 1/num_select[iter]
### calculate fdp and power
result <- CalculateFDP_Power(selected_index, signal_index)
fdp[iter] <- result$fdp
power[iter] <- result$power
}
}
### single data-splitting (DS) result
DS_fdp <- fdp[1]
DS_power <- power[1]
### multiple data-splitting (MDS) result
inclusion_rate <- apply(inclusion_rate, 2, mean)
### rank the features by the empirical inclusion rate
feature_rank <- order(inclusion_rate)
feature_rank <- setdiff(feature_rank, which(inclusion_rate == 0))
if(length(feature_rank)!=0){
null_feature <- numeric()
### backtracking
for(feature_index in 1:length(feature_rank)){
if(sum(inclusion_rate[feature_rank[1:feature_index]]) > q){
break
}else{
null_feature <- c(null_feature, feature_rank[feature_index])
}
}
selected_index <- setdiff(feature_rank, null_feature)
### calculate fdp and power
result <- CalculateFDP_Power(selected_index, signal_index)
MDS_fdp <- result$fdp
MDS_power <- result$power
}
else{
MDS_fdp <- 0
MDS_power <- 0
}
return(list(DS_fdp = DS_fdp, DS_power = DS_power, MDS_fdp = MDS_fdp, MDS_power = MDS_power))
}
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
#mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleLinRegTrainMS.R'))
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(MASS)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
library(dplyr)
library(ggplot2)
library(ggpubr)
### algorithmic settings
num_split <- 10
n <-1500
p <- 250
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
################################Triange: train test test each 30####################################
Compare_SignalStrength=function(i,s){
set.seed(s)
ResultsDataFrame=data.frame()
delta <- i
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
### randomly generate the true beta i=4
beta_star <- rep(0, p)
beta_star[signal_index] <- rnorm(p0, mean = 0, sd = delta*sqrt(log(p)/n))
### generate y
y <- X%*%beta_star + rnorm(n, mean = 0, sd = 1)
###my own methods:
g=ApplyTriangleLinRegTrain(X=as.data.frame(X), y, q=0.1,num_split=10, signal_index=signal_index, amountTrain=0.333, myseed = 1)
ResultsDataFrame=c('LinReg DS',i, as.numeric(g$DS_fdp),as.numeric(g$DS_power))
ResultsDataFrame=rbind(ResultsDataFrame,c('LinReg MS',i, as.numeric(g$MDS_fdp),as.numeric(g$MDS_power)))
### Competition
DS_result <- DS(X,y, num_split=10, q=0.1)
ResultsDataFrame=rbind(ResultsDataFrame,c('DataSplitting',i,DS_result$DS_fdp,DS_result$DS_power))
ResultsDataFrame=rbind(ResultsDataFrame,c('MultipleDataSplitting',i,DS_result$MDS_fdp,DS_result$MDS_power))
knockoff_result <- knockoff(X, y, q=0.1)
ResultsDataFrame=rbind(ResultsDataFrame,c('Knockoff',i,knockoff_result$fdp,knockoff_result$power))
BH_result <- MBHq(X, y, q=0.1, num_split)
ResultsDataFrame=rbind(ResultsDataFrame,c('BH',i,BH_result$fdp,BH_result$power))
### save data
return(ResultsDataFrame)}
library(parallel)
mywd <- 'C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
setwd(mywd)
# Source helper and method files
source(file.path(mywd, 'Functions','HelperFunctions.R'))
source(file.path(mywd, 'Functions', 'TriangleLinRegTrainMS.R'))
# Dai’s routines
source(file.path(mywd, 'Functions Dai', 'knockoff.R'))
source(file.path(mywd, 'Functions Dai', 'analysis.R'))
source(file.path(mywd, 'Functions Dai', 'MBHq.R'))
source(file.path(mywd, 'Functions Dai', 'DS.R'))
source(file.path(mywd, 'Functions Dai', 'fdp_power.R'))
# Load required packages
pkgs <- c('xgboost','gbm','ranger','MASS','glmnet','knockoff','mvtnorm','hdi',
'foreach','doParallel')
lapply(pkgs, library, character.only = TRUE)
# === PARAMETER GRID ===
param_grid <- expand.grid(
s = 1:50,
i = seq(from = 7, to = 13, by = 1)
)
# === SET UP PARALLEL BACKEND ===
cl <- makeCluster(detectCores() - 4)
# export working dir so workers can source
clusterExport(cl, 'mywd')
# have each worker source & load libraries
clusterEvalQ(cl, {
setwd(mywd)
source(file.path(mywd, 'Functions', 'HelperFunctions.R'))
source(file.path(mywd, 'Functions', 'TriangleLinRegTrainMS.R'))
source(file.path(mywd, 'Functions Dai', 'knockoff.R'))
source(file.path(mywd, 'Functions Dai', 'analysis.R'))
source(file.path(mywd, 'Functions Dai', 'MBHq.R'))
source(file.path(mywd, 'Functions Dai', 'DS.R'))
source(file.path(mywd, 'Functions Dai', 'fdp_power.R'))
lapply(c('xgboost','gbm','ranger','MASS','glmnet','knockoff','mvtnorm','hdi'),
library, character.only = TRUE)
})
registerDoParallel(cl)
# === RUN IN PARALLEL AND WRITE OUT ===
results_list <- foreach(
k = seq_len(nrow(param_grid)),
.packages = pkgs,
.combine  = rbind
) %dopar% {
s_val <- param_grid$s[k]
i_val <- param_grid$i[k]
# compute chunk of results
chunk <- Compare_SignalStrength(i = i_val, s = s_val)
# write out this chunk immediately
fname <- sprintf("Results_s%02d_i%02d.csv", s_val, i_val)
write.csv(chunk, file = fname, row.names = FALSE)
# return for final binding
chunk
}
# === CLEANUP AND FINAL SAVE ===
stopCluster(cl)
warnings()
# combine all and save full dataset
Results <- results_list
write.csv(Results, file = "All_Results.csv", row.names = FALSE)
Results=data.frame()
for(s in 1:25){
for(i in seq(from=5,to=13,by=1)){
Results=rbind(Results,Compare_SignalStrenght(i,s))
print(Results)
}
}
Results
results_list
write.csv(Results, file = "All_Results_VanillaLinear.csv", row.names = FALSE)
names(Results)
names(Results)=c('Method','SignalStrength', 'FDR','Power')
Results
# combine all and save full dataset
Results <- results_list
Results
names(Results)=c('Method','SignalStrength', 'FDR','Power')
Results
# combine all and save full dataset
Results <- results_list
Results
#write.csv(Results, file = "All_Results_vanillaLinear.csv", row.names = FALSE)
Results=as.data.frame(Results)
names(Results)
names(Results)=c('Method','SignalStrength', 'FDR','Power')
Results
head(Results)
write.xlsx(Results,file='~/Results/VanillaScenarioLMTriangle.xlsx')
library(openxlsx)
library(xlsx)
install.packages("openxlsx")
library(openxlsx)
write.xlsx(Results,file='~/Results/VanillaScenarioLMTriangle.xlsx')
Results
write.xlsx(Results,file='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting/Results/VanillaScenarioLMTriangle.xlsx')
####Visualise the results
# Create a color palette based on the number of unique methods
Results2=Results
#Results=read.xlsx('VanillaResults.xlsx')
colors <- c("#FF0000", "#00FF00", "#0000FF", "#000000", "#FF00FF", )
sort(unique(Results2$Method))
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
#Results2=subset(Results2,SignalStrength%in%as.character(7:13))
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
View(resultsagg)
resultsagg$Signal_noisy <- as.numeric(resultsagg$SignalStrength) + runif(nrow(resultsagg), -0.2, 0.2)
resultsagg <- resultsagg %>%
mutate(Method  = case_when(
Method == "BH" ~ "Benjamini–Hochberg",
Method == "DataSplitting" ~ "Dai (single split)",
Method == "MultipleDataSplitting" ~ "Dai (10 splits)",
Method == "Knockoff" ~ "Knockoff",
Method == "LinReg DS" ~ "Delporte (single split)",
Method == "LinReg MS" ~ "Delporte (10 splits)",
TRUE ~ Method  # default if none match
))
PowerPlot <- ggplot(resultsagg, aes(x = Signal_noisy, y = as.numeric(Avg_Power), color = Method)) +
geom_point(size = 3) +
geom_line()+
labs(x = "Signal", y = "Power") +
scale_x_continuous(breaks = seq(from = 3, to = 13, by = 1)) +
geom_hline(yintercept = 0.8) +
scale_color_manual(values = colors)+
coord_cartesian(ylim = c(0.1, 1))
FDRPlot=ggplot(resultsagg, aes(x = Signal_noisy, y = as.numeric(Avg_FDR ), color = Method)) +
geom_point(size = 3) +
geom_line()+
labs(x = "Signal", y = "FDP")+
scale_x_continuous(breaks=seq(from=3,to=13,by=1))+
geom_hline(yintercept=0.1)+
scale_color_manual(values = colors)
PlotPermute=ggarrange(
PowerPlot, FDRPlot,
common.legend = TRUE, legend = "right"
)
PlotPermute
mean(y[sample_index1]))
mean(y[sample_index1])
