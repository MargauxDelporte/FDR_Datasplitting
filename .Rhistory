##8. Compute w1, w2 and Combined Log-RR
final_df <- final_df %>%
mutate(
# For convenience in R, define these "pieces" at each time i
# per your snippet:  (1 - S02_bar) factor, log(S01_bar), etc.
part_beta1_num = S01_bar * h01_bar * (1 - S02_bar) * log(S01_bar),
part_beta1_den = S01_bar * h01_bar * (1 - S02_bar),
part_beta2_num = S01_bar * h01_bar * S02_bar * log(1 / S02_bar),
part_beta2_den = S01_bar * h01_bar * S02_bar  # or same as beta1_den?
)
final_df
##8. Compute w1, w2 and Combined Log-RR
final_df <- final_df %>%
mutate(
# For convenience in R, define these "pieces" at each time i
# per your snippet:  (1 - S02_bar) factor, log(S01_bar), etc.
part_beta1_num = S01_bar * h01_bar * (1 - S02_bar) * log(S01_bar),
part_beta1_den = S01_bar * h01_bar * (1 - S02_bar),
part_beta2_num = S01_bar * h01_bar * S02_bar * log(1 / S02_bar),
part_beta2_den = S01_bar * h01_bar * S02_bar  # or same as beta1_den?
)
# Sum across i=1..8 (i.e., time > 0)
sum_df <- final_df %>%
filter(time_yr >= 1 & time_yr <= 8) %>%
summarise(
beta1_num = sum(part_beta1_num, na.rm=TRUE),
beta1_den = sum(part_beta1_den, na.rm=TRUE),
beta2_num = sum(part_beta2_num, na.rm=TRUE),
beta2_den = sum(part_beta2_den, na.rm=TRUE)
)
sum_df
w1 <- 1 + (sum_df$beta1_num / sum_df$beta1_den)
w2 <-      sum_df$beta2_num / sum_df$beta2_den
w1; w2
log_RR    <- incid_beta1 * w1 + mort_beta1 * w2
##8. Compute w1, w2 and Combined Log-RR
final_df <- final_df %>%
mutate(
# For convenience in R, define these "pieces" at each time i
# per your snippet:  (1 - S02_bar) factor, log(S01_bar), etc.
part_beta1_num = S01_bar * h01_bar * (1 - S02_bar) * log(S01_bar),
part_beta1_den = S01_bar * h01_bar * (1 - S02_bar),
part_beta2_num = S01_bar * h01_bar * S02_bar * log(1 / S02_bar),
part_beta2_den = S01_bar * h01_bar * S02_bar  # or same as beta1_den?
)
final_df
# create the weights (sum until t)
df_with_w <- df %>%
mutate(
# cumulative sums of beta1 parts
cum_beta1_num = cumsum(part_beta1_num),
cum_beta1_den = cumsum(part_beta1_den),
# w1(t) = [ sum of part_beta1_num up to t ] / [ sum of part_beta1_den up to t ]
w1 = 1+ cum_beta1_num / cum_beta1_den,
# cumulative sums of beta2 parts
cum_beta2_num = cumsum(part_beta2_num),
cum_beta2_den = cumsum(part_beta2_den),
# w2(t) = [ sum of part_beta2_num up to t ] / [ sum of part_beta2_den up to t ]
w2 = cum_beta2_num / cum_beta2_den
)
# create the weights (sum until t)
df_with_w <- final_df %>%
mutate(
# cumulative sums of beta1 parts
cum_beta1_num = cumsum(part_beta1_num),
cum_beta1_den = cumsum(part_beta1_den),
# w1(t) = [ sum of part_beta1_num up to t ] / [ sum of part_beta1_den up to t ]
w1 = 1+ cum_beta1_num / cum_beta1_den,
# cumulative sums of beta2 parts
cum_beta2_num = cumsum(part_beta2_num),
cum_beta2_den = cumsum(part_beta2_den),
# w2(t) = [ sum of part_beta2_num up to t ] / [ sum of part_beta2_den up to t ]
w2 = cum_beta2_num / cum_beta2_den
)
df_with_w
#quick test
w13=1+((-0.001490956-0.003103562-0.004897851)/( 0.01671491+0.01657850+0.01650778)
# Sum across i=1..8 (i.e., time > 0)
sum_df <- final_df %>%
#quick test
w13=1+((-0.001490956-0.003103562-0.004897851)/( 0.01671491+0.01657850+0.01650778))
w23=(0.01478172+ 0.01466109-0.01459855)/(0.06133939+0.06083882+0.06057930)
w13
w23
df_with_w
#quick test
w13=1+((-0.001490956-0.003103562)/( 0.01671491+0.01657850))
w23=(0.01478172+ 0.01466109)/(0.06133939+0.06083882)
w13
w23
#quick test
w13=1+((-0.001490956-0.003103562)/( 0.01671491+0.01657850))
w23=(0.01478172+ 0.01466109)/(0.06133939+0.06083882)
# create the weights (sum until t)
df_with_w <- df %>%
mutate(
# 1) Full cumulative sums including current row
csum_b1_num = cumsum(part_beta1_num),
csum_b1_den = cumsum(part_beta1_den),
csum_b2_num = cumsum(part_beta2_num),
csum_b2_den = cumsum(part_beta2_den),
# 2) SHIFT those sums by 1 row, so row i sees sum up to i-1
cum_beta1_num_prev = dplyr::lag(csum_b1_num, default = 0),
cum_beta1_den_prev = dplyr::lag(csum_b1_den, default = 0),
cum_beta2_num_prev = dplyr::lag(csum_b2_num, default = 0),
cum_beta2_den_prev = dplyr::lag(csum_b2_den, default = 0),
# 3) Compute w1 and w2 using the sums up to i-1
w1 = 1+(cum_beta1_num_prev / cum_beta1_den_prev),
w2 = cum_beta2_num_prev / cum_beta2_den_prev
)
# create the weights (sum until t)
df_with_w <- final_df %>%
mutate(
# 1) Full cumulative sums including current row
csum_b1_num = cumsum(part_beta1_num),
csum_b1_den = cumsum(part_beta1_den),
csum_b2_num = cumsum(part_beta2_num),
csum_b2_den = cumsum(part_beta2_den),
# 2) SHIFT those sums by 1 row, so row i sees sum up to i-1
cum_beta1_num_prev = dplyr::lag(csum_b1_num, default = 0),
cum_beta1_den_prev = dplyr::lag(csum_b1_den, default = 0),
cum_beta2_num_prev = dplyr::lag(csum_b2_num, default = 0),
cum_beta2_den_prev = dplyr::lag(csum_b2_den, default = 0),
# 3) Compute w1 and w2 using the sums up to i-1
w1 = 1+(cum_beta1_num_prev / cum_beta1_den_prev),
w2 = cum_beta2_num_prev / cum_beta2_den_prev
)
df_with_w
cum_beta1_num_prev
cum_beta1_den_prev
# create the weights (sum until t)
df_with_w <- final_df %>%
mutate(
# 1) Full cumulative sums including current row
csum_b1_num = cumsum(part_beta1_num),
csum_b1_den = cumsum(part_beta1_den),
csum_b2_num = cumsum(part_beta2_num),
csum_b2_den = cumsum(part_beta2_den),
# 2) SHIFT those sums by 1 row, so row i sees sum up to i-1
cum_beta1_num_prev = dplyr::lag(csum_b1_num, default = 0),
cum_beta1_den_prev = dplyr::lag(csum_b1_den, default = 0),
cum_beta2_num_prev = dplyr::lag(csum_b2_num, default = 0),
cum_beta2_den_prev = dplyr::lag(csum_b2_den, default = 0),
# 3) Compute w1 and w2 using the sums up to i-1
w1 = 1+(cum_beta1_num_prev / cum_beta1_den_prev),
w2 = cum_beta2_num_prev / cum_beta2_den_prev
)
#quick test
w13=1+((-0.001490956-0.003103562)/( 0.01671491+0.01657850))
w23=(0.01478172+ 0.01466109)/(0.06133939+0.06083882)
w13
w23
df_with_w
#quick test
w13=1+((-0.001490956-0.000000000)/( 0.01671491+0.00000000))
w13
w23=(0.01478172+0.000000000)/(0.06133939+0.000000000)
w23
w13=1+((-0.001490956-0.003103562)/( 0.01671491+0.01657850))
w23=(0.01478172+0.01466109)/(0.06133939+0.06083882)
w13
w23
incid_beta1
w1
mort_beta1
w2
df_with_w
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
log_RR
#create the logrisk ratios for each timepoint
results_df=data.frame()
results_df
cbind(results_df,log_RR,exp(log_RR))
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
results_df=data.frame(cbind(log_RR,exp(log_RR)))
results_df
incid_stderr1
mort_stderr1
var_logRR <- (df_with_w$w1^2)*(incid_stderr1^2) + (df_with_w$w2^2)*(mort_stderr1^2)
var_logRR
results_df=cbind(results_df,var_logRR)
results_df$lcl_logRR <- results_df$log_RR - 1.96 * sqrt(results_df$var_logRR)
results_df$ucl_logRR <- results_df$log_RR + 1.96 * sqrt(results_df$var_logRR)
results_df
#create the logrisk ratios for each timepoint
log_RR    <- incid_beta1 * df_with_w$w1 + mort_beta1 *df_with_w$w2
results_df=data.frame(cbind(log_RR))
var_logRR <- (df_with_w$w1^2)*(incid_stderr1^2) + (df_with_w$w2^2)*(mort_stderr1^2)
results_df=cbind(results_df,var_logRR)
# Confidence intervals
se_logRR  <- sqrt(var_logRR)
results_df$lcl_logRR <- results_df$log_RR - 1.96 * sqrt(results_df$var_logRR)
results_df$ucl_logRR <- results_df$log_RR + 1.96 * sqrt(results_df$var_logRR)
results_df
# Exponentiated version (RR scale)
RR       <- exp(log_RR)
RR_lower <- exp(lcl_logRR)
RR_upper <- exp(ucl_logRR)
# Exponentiated version (RR scale)
results_df$RR       <- exp(results_df$log_RR)
results_df$RR_lower <- exp(results_df$lcl_logRR)
results_df$RR_upper <- exp(results_df$ucl_logRR)
results_df
# p-value
z_score  <- log_RR / se_logRR
p_val    <- 2 * (1 - pnorm(abs(z_score)))
list(
w1 = w1,
w2 = w2,
log_RR = log_RR,
RR     = RR,
CI     = c(RR_lower, RR_upper),
pvalue = p_val
)
results_df
# p-value
results_df$z_score  <- results_df$log_RR / results_df$se_logRR
results_df$se_logRR
sqrt(results_df$var_logRR)
# p-value
results_df$z_score  <- results_df$log_RR / sqrt(results_df$var_logRR)
results_df$p_val    <- 2 * (1 - pnorm(abs(results_df$z_score)))
results_df
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol<-read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Datafracpol2.sas7bdat",
NULL)
#fracpol <- read_sas("C:/Users/u0118563/OneDrive - KU Leuven/Projecten/Rare diseases/Data/fracpol2.sas7bdat",
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
response <- "foc_01"
poww1 <- "minushalf"
poww2 <- "plushalf"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='uni_01', age_var='age', gender_var='Sex', id_var="id")
# Display the plots
ggarrange(plots$spaghetti_plot,plots$loess_plot,ncol=2)
plots$loess_plot
plots
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
library(xtable)
#                    NULL)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
response <- "uni_01"
poww1 <- "minus2"
poww2 <- "plus1"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='uni_01', age_var='age', gender_var='Sex', id_var="id")
plots
plots
library(lme4)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(haven)
fracpol <- read_sas("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/KUL/Rare diseases/Rare diseases/Data/fracpol2.sas7bdat",
NULL)
#recode the responses
recode=function(x){
ifelse(x=='Yes',1,0)
}
fracpol$gen_01=sapply(as.vector(fracpol$gen_bin),FUN=recode)
fracpol$uni_01=sapply(as.vector(fracpol$uni_bin),FUN=recode)
fracpol$foc_01=sapply(as.vector(fracpol$foc_bin),FUN=recode)
#Sex variable
recode=function(x){
ifelse(x=='F','Female','Male')
}
fracpol$Sex=sapply(as.vector(fracpol$sex),FUN=recode)
# Define the model formula
fracpol$log_plushalf=fracpol$log*fracpol$plushalf
response <- "gen_01"
poww1 <- "plushalf"
poww2 <- "log_plushalf"
formula <- as.formula(paste('as.factor(', response, ")~", "+ baseline_age + Male + mut_Other + mutPCDH19 +", poww1, "+",
paste(poww1, "*", c("baseline_age", "Male"), collapse = "+"), "+",
poww2, "+", paste(poww2, "*", c("baseline_age", "Male"), collapse = "+"), '+(1|id)'))
# Fit the initial model with less strict convergence criterion
initial_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000), tolPwrss = 1e-3)
initial_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 1, control = initial_control_settings)
# Extract the fixed effect coefficients and random effect variances
#initial_model=final_model
start_vals <- list(fixef = fixef(initial_model), theta = getME(initial_model, "theta"))
# Fit the final model with stricter convergence criterion and using initial parameter estimates
final_control_settings <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))
final_model <- glmer(formula, data = fracpol, family = binomial(link = "probit"), nAGQ = 5, start = start_vals, control = final_control_settings)
fracpol$age=fracpol$baseline_age+fracpol$time
fracpol<-fracpol[!(is.na(fracpol$mutPCDH19)),]
# Function to create visualizations
visualize_results <- function(model, data=fracpol, response, age_var = "age", gender_var = "Sex", id_var = "id") {
# Create a new data frame with the original data and predicted values
data_with_preds <- data %>%
mutate(predicted = predict(model, type = "response"),
fitted = predict(model, re.form = NA, type = "response"))
# Spaghetti plot of predicted values
loess_plot <- ggplot(data_with_preds, aes_string(x = age_var, y = "fitted", color = gender_var)) +
geom_smooth(method = "loess", se = FALSE, size = 2) +  # Thick lines
ylim(0, 1) +
labs(title = "Predicted Probability by Age",
x = "Age",
y = "Predicted Probability") +
theme_minimal(base_size = 18) +  # Larger text
theme(
axis.title = element_text(face = "bold", size = 20),
axis.text = element_text(size = 18),
legend.title = element_text(face = "bold", size = 18),
legend.text = element_text(size = 16),
plot.title = element_text(face = "bold", size = 22, hjust = 0.5)
)
return(loess_plot)
}
# Visualize the results
plots <- visualize_results(final_model, fracpol, response='gen_01', age_var='age', gender_var='Sex', id_var="id")
plots$loess_plot
# Display the plots
ggarrange(plots$spaghetti_plot,plots$loess_plot,ncol=2)
plots
4563/365
3650/365
1825/365
8/1.6
96/5
64/3.5
i=1
0.05/(5-i+1)
i=2
0.05/(5-i+1)
i=3
0.05/(5-i+1)
i=4
0.05/(5-i+1)
i=5
0.05/(5-i+1)
i=5
0.05/(5-i+1)
i=1
0.05/(5-i+1)
90-(18.25+19.35+28.25)
param_grid <- expand.grid(
learning_rate = c(0.01, 0.05, 0.1),
max_depth = c(3, 5, 7),
num_leaves = c(15, 31, 63),  # must be < 2^max_depth
lambda_l1 = c(0, 1, 5),
lambda_l2 = c(0, 1, 5),
min_data_in_leaf = c(10, 20, 50),
feature_fraction = c(0.6, 0.8, 1.0),
bagging_fraction = c(0.6, 0.8, 1.0),
bagging_freq = c(1)  # how often to apply bagging
)
param_grid
nrow(param_grid)
5.49/12
2.29/64
4.49/96
445+237
exp(0.127)
exp(0.572)
94074/43.3*100
94074/43.3*100-94074
### High dimensional non-linear case
rm(list = ls())
#mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/TriangleBoosterHDNL.R'))
#mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleBoosterHDNL.R'))
#mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source(paste0(mywd,'/Functions/TriangleBoosterHDNL.R'))
### algorithmic settings
num_split <- 1
n <-1500
p <- 2000
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
