aggregate(d[, 2:7], list(d$V1), mean)
aggregate(d[2:7], list(d$V1), mean)
d %>%
group_by(V1) %>%
summarise_at(funs(mean(., na.rm=TRUE)))
d %>%
group_by(V4) %>%
summarise(across(mean, na.rm = TRUE))
colmean(check, group = v1)
install.packages("analytics")
library(analytics)
agg_tbl <- check %>% group_by(V1) %>%
summarise(mean_salary=mean(X1),
.groups = 'drop')
agg_tbl
agg_tbl <- check %>% group_by(V1) %>%
summarise(mean_X1=mean(X1),
.groups = 'drop')
df2 <- num_df %>% group_by(V1) %>%
summarise(across(everything(), mean),
.groups = 'drop')  %>%
as.data.frame()
df2 <- check %>% group_by(V1) %>%
summarise(across(everything(), mean),
.groups = 'drop')  %>%
as.data.frame()
df2
# Suppose true event time is T, and we split at cuts (before T)
library(survival)
long <- survSplit(Surv(time, event) ~ x1 + x2, data = df,
cut = c(1, 2, 5), # example cut times
episode = "k", id = "id")
airquality
ovarian
?ovarian
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
fit <- coxph(Surv(futime, fustat) ~  age + rx  + cluster(id), data = ovarian )
summary(fit)
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
fit <- coxph(Surv(futime, fustat) ~  age + rx , data = ovarian )
summary(fit)
futime
ovarian$futime
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
ovarian$uncensored
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
ovarian$uncensored=rep(1,nrow(ovarian))
fit <- coxph(Surv(futime, uncensored) ~  age + rx , data = ovarian )
summary(fit)
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
ovarian$uncensored=rep(1,nrow(ovarian))
fit <- coxph(Surv(futime, uncensored) ~  age + rx , data = ovarian )
summary(fit)
ovarian2$addedtime=runif(min(ovarian$futime),max(ovarian$futime))
runif(min(ovarian$futime),max(ovarian$futime))
min(ovarian$futime)
max(ovarian$futime)
?runif
ovarian2$addedtime=runif(n=nrow(ovarian,min=min(ovarian$futime),max=max(ovarian$futime)))
ovarian2$addedtime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
ovarian$addedtime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
ovarian2=ovarian
ovarian2$addedtime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
set.seed(123)
ovarian$uncensored=rep(1,nrow(ovarian))
fit <- coxph(Surv(futime, uncensored) ~  age + rx , data = ovarian )
summary(fit)
ovarian2=ovarian
ovarian2$addedtime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
ovarian2=ovarian
ovarian2$futime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
# survSplit creates tstart/tstop, sets event=1 only for interval containing T
set.seed(123)
ovarian$uncensored=rep(1,nrow(ovarian))
fit <- coxph(Surv(futime, uncensored) ~  age + rx , data = ovarian )
summary(fit)
ovarian2=ovarian
ovarian2$futime=runif(n=nrow(ovarian), min=min(ovarian$futime), max=max(ovarian$futime))
fit <- coxph(Surv(futime, fustat) ~  age + rx , data = rbind(ovarian,ovarian2))
summary(fit)
# library(devtools)
# remotes::install_github("YushuShi/correctedC")
library(correctedC)
library(survminer)
library(dplyr)
library(tableone)
library(reticulate)
library(survivalmodels)
library(survival)
library(devtools)
library(survivalContour)
library(randomForestSRC)
library(fastDummies)
library(readr)
source('C:/Users/mde4023/Documents/GitHub/StackedSurvivalData/CreateStack.R')
#use_condaenv("/Users/yushushi/opt/anaconda3/envs/tensorflow", required = TRUE)
use_condaenv("C:/Users/mde4023/AppData/Local/anaconda3/envs/tensorflow", required = TRUE)
data=ovarian
#processing data
names(data)
data$Status=data$fustat
?ovarian
# Other variables
other_vars <- c(
"age", "resid.ds", "rx", "ecog.ps"
)
# Combine dummy variables and other predictors
all_vars <- c(dummy_vars, other_vars)
data$N_Days=data$futime
# Other variables
other_vars <- c(
"age", "resid.ds", "rx", "ecog.ps"
)
# Combine dummy variables and other predictors
all_vars <- c(dummy_vars, other_vars)
ovarian
data=ovarian
#processing data
names(data)
data$Status=data$fustat
data$N_Days=data$futime
data$resid.ds=data$resid.ds-1
data$rx=data$rx-1
data$ecog.ps=data$ecog.ps-1
# Other variables
other_vars <- c(
"age", "resid.ds", "rx", "ecog.ps"
)
# Combine dummy variables and other predictors
all_vars <- c(other_vars)
all_vars
# Create the new formula
formula_str <- paste("Surv(N_Days, Status) ~", paste(all_vars, collapse = " + "))
myformula <- as.formula(formula_str)
#only select relevant variables in the data
mydata=data[,c('N_Days', 'Status', all_vars)]
coxph(myformula,data=mydata)
#function to stack the data
CreateStack=function(data,nrep){
ntest<-floor(nrow(data)/10)
trainIndex <- sample(1:nrow(data), nrow(data)-ntest)
testIndex <- setdiff(1:nrow(data), trainIndex)
trainData <- data[trainIndex,]
testData <- data[testIndex,]
stacked_df <- do.call(rbind, replicate(nrep, trainData, simplify = FALSE))
maxTime<-max(trainData$N_Days[trainData$Status==1])
timeCens<-runif(nrow(stacked_df),0,maxTime)
timeComp<-timeCens<stacked_df$N_Days
stacked_df$N_Days[timeComp]<-timeCens[timeComp]
stacked_df$Status<-ifelse(timeComp,
rep(0,nrow(stacked_df)),
stacked_df$Status)
stacked_df<-rbind(stacked_df,trainData)
return(list(
stacked_df=stacked_df,
testData=testData,
trainData=trainData
))
}
simFunction<-function(data,seedNum,nrep){
set.seed(seedNum)
DataSeg=CreateStack(data,nrep =nrep)
rfModel1 <- rfsrc(myformula,DataSeg$stacked_df)
rfModel2 <- rfsrc(myformula,DataSeg$trainData)
rfPred1 <- predict(rfModel1,newdata = DataSeg$testData)
rfPred2 <- predict(rfModel2,newdata = DataSeg$testData)
rfC1<-UnoC(DataSeg$testData$N_Days, DataSeg$testData$Status,  rfPred1$predicted)
rfC2<-UnoC(DataSeg$testData$N_Days, DataSeg$testData$Status,  rfPred2$predicted)
c(rfC1,rfC2)
}
CVresult<-NULL
for(i in 1:150){
CVresult<-rbind(CVresult,simFunction(mydata,i,nrep = 20))
print(i)
}
CVresult
DataSeg=CreateStack(data,nrep =nrep)
DataSeg
rfModel1 <- rfsrc(myformula,DataSeg$stacked_df)
rfModel2 <- rfsrc(myformula,DataSeg$trainData)
rfPred1 <- predict(rfModel1,newdata = DataSeg$testData)
rfPred2 <- predict(rfModel2,newdata = DataSeg$testData)
rfC1<-UnoC(DataSeg$testData$N_Days, DataSeg$testData$Status,  rfPred1$predicted)
rfC2<-UnoC(DataSeg$testData$N_Days, DataSeg$testData$Status,  rfPred2$predicted)
rfC1
rfC2
UnoC
1-7/8
0.125 * (1 - 1/7)
1 * (1 - 1/8)
0.875 * (1 - 1/8)
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Alt/Temp"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
#View(subset(Results2,Results2$Method=='Mars MS'))
##########visualise the results###########
library(ggplot2)
library(dplyr)
library(ggpubr)
library(readr)
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Alt/Temp"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
#View(subset(Results2,Results2$Method=='Mars MS'))
##########visualise the results###########
library(ggplot2)
library(dplyr)
library(ggpubr)
library(readr)
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg$Signal_noisy <- as.numeric(resultsagg$SignalStrength) + runif(nrow(resultsagg), -0.2, 0.2)
View(resultsagg)
resultsagg
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Alt/Temp"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
#View(subset(Results2,Results2$Method=='Mars MS'))
##########visualise the results###########
library(ggplot2)
library(dplyr)
library(ggpubr)
library(readr)
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Temp"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
#View(subset(Results2,Results2$Method=='Mars MS'))
##########visualise the results###########
library(ggplot2)
library(dplyr)
library(ggpubr)
library(readr)
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg$Signal_noisy <- as.numeric(resultsagg$SignalStrength) + runif(nrow(resultsagg), -0.2, 0.2)
View(resultsagg)
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Temp2"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
#View(subset(Results2,Results2$Method=='Mars MS'))
##########visualise the results###########
library(ggplot2)
library(dplyr)
library(ggpubr)
library(readr)
mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
mywd <- paste0(mywd,'/Results')
colors <- c("#000000","#FF00FF","#009900", "#99ccff", "#0000FF", "#FF0000")
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg$Signal_noisy <- as.numeric(resultsagg$SignalStrength) + runif(nrow(resultsagg), -0.2, 0.2)
View(resultsagg)
# Path to your folder
csv_dir <- "C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Temp"
csv_files <- list.files(
path       = csv_dir,
pattern    = "\\.csv$",
full.names = TRUE
)
warnings()
# Get full paths of all .csv files
# Read each file into a list of data.frames
data_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)
library(dplyr)
library(openxlsx)
all_data <- bind_rows(data_list, .id = "source_file")
#write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_HDNL_q25.xlsx')
Results=all_data
Results
Results2=Results
names(Results2)=c('seed','Method','SignalStrength','FDR','Power')
Results2$FDR=round(as.numeric(Results2$FDR),3)
Results2$Power=round(as.numeric(Results2$Power),2)
resultsagg <- Results2 %>%
group_by(Method, SignalStrength) %>%
summarize(
Avg_FDR = mean(FDR),
Avg_Power = mean(Power)
)
resultsagg
all_data
write.xlsx(all_data,file='C:/Users/mde4023/Downloads/FDR_Datasplitting/Results/Mars_NL.xlsx')
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting'
#mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
#mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/HD NL plus1weg/FS.R')
source(paste0(mywd,'/Functions/TriangleBoosterTrainMS.R'))
source(paste0(mywd,'/Functions/ApplyGBMKnockoff.R'))
source(paste0(mywd,'/FDR_Datasplitting/HD NL plus1weg/MarsParallelHD.R'))
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/Downloads/FDR_Datasplitting'
#mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
#mywd='C:/Users/marga/Downloads/FDR_Datasplitting'
setwd(mywd)
source(paste0(mywd,'/Functions/HelperFunctions.R'))
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/HD NL plus1weg/FS.R')
source(paste0(mywd,'/Functions/TriangleBoosterTrainMS.R'))
source(paste0(mywd,'/Functions/ApplyGBMKnockoff.R'))
source('C:/Users/mde4023/Downloads/FDR_Datasplitting/HD NL plus1weg/MarsParallelHD.R')
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
#algorithmic settings
num_split <- 50
n <-400
p <- 500
p0 <- 10#25
q <- 0.10
delta <- 10
amountTest=0.5
amountTrain=0.5
###choose the parameters
params =list(
objective = "reg:squarederror",
eta       = 0.005,
max_depth = 6,
lambda    = 0,
alpha     = 0
)
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
#######set up the method for the comparison############# i=10 s=10 num_split=1
Compare_SignalStrength <- function(i, s,other=T) {
set.seed(s)
delta <- i
signal_index <- sample(c(1:p), size = p0, replace = F)
# simulate data
n1 <- floor(n/2); n2 <- n - n1
X1 <- matrix(rnorm(n1*p, mean= 1), n1, p)
X2 <- matrix(rnorm(n2*p, mean=-1), n2, p)
X  <- rbind(X1, X2)
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*1000
y <- (X^2 %*% beta_star+ rnorm(n))
# run your custom methods
g1 <- ApplyMarsTrain_HDparallel( X = X, y = y, q = q, num_split = num_split,signal_index = signal_index, myseed = 1)
# FDR methods
if(other){
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- ApplyGBMKnockoff(    X = X, y = y, q = q,param=params)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
}
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Mars DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Mars MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power))
if(other){
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjaminiâ€“Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
}
return(ResultsDataFrame)
}
Compare_SignalStrength(7,7,F)
