# Assign columns
colnames(mydata) <- c("eid", "enrollment_date",
"rorp_prs_norm", "prs_breast_cancer",
"incident_breast_cancer_cr", "time_to_incident_bc_days_cr",
"bc_death_cr", "time_to_bc_death_days_cr")
dim(mydata)
head(mydata, 5)
#create variables
mydata <- mydata %>%
mutate(
time_inc   = time_to_incident_bc_days_cr,
status_inc = incident_breast_cancer_cr,
time_mort  = time_to_bc_death_days_cr,
status     = bc_death_cr
)
# For Fine-Gray subdistribution hazard modeling
# install.packages("cmprsk")  # if not already installed
library(cmprsk)
library(QHScrnomo)
# For data wrangling
library(dplyr)
library(ggplot2)
library(tidyr)
library(riskRegression)
# Use read.table with textConnection to emulate your SAS datalines
mydata <- read.table(
textConnection("
101 01JAN2010 0.45 0.25 1 730 0 .
102 14FEB2011 0.55 0.45 0 . 1 2500
103 30APR2012 0.68 0.52 1 1600 1 2400
104 05MAY2013 0.25 0.10 1 3000 2 .
105 10OCT2014 0.99 0.80 0 . 0 .
106 12DEC2015 0.40 0.20 1 1000 0 .
107 23JUN2016 0.77 0.60 1 2200 1 4000
108 28SEP2017 0.50 0.38 0 . 2 .
109 05JAN2018 0.63 0.42 1 1400 0 .
110 19NOV2019 0.33 0.25 1 3700 1 5500
111 26MAR2020 0.81 0.65 2 430 0 .
112 07JUL2021 0.58 0.40 1 1850 0 .
113 15FEB2022 0.72 0.55 0 . 2 .
114 01MAY2023 0.95 0.78 1 2800 0 .
115 31DEC2024 0.61 0.47 1 360 2 600
"),
header = FALSE,
na.strings = ".",
stringsAsFactors = FALSE
)
# Assign columns
colnames(mydata) <- c("eid", "enrollment_date",
"rorp_prs_norm", "prs_breast_cancer",
"incident_breast_cancer_cr", "time_to_incident_bc_days_cr",
"bc_death_cr", "time_to_bc_death_days_cr")
dim(mydata)
head(mydata, 5)
#create variables
mydata <- mydata %>%
mutate(
time_inc   = time_to_incident_bc_days_cr,
status_inc = incident_breast_cancer_cr,
time_mort  = time_to_bc_death_days_cr,
status     = bc_death_cr
)
mydata
# Filter out rows with missing time so crr doesn't break
df_incid <- mydata %>%
filter(!is.na(time_inc) & !is.na(status_inc))
df_incid$rorp_prs_norm
df_incid$prs_breast_cancer
summary(df_incid$prs_breast_cancer)
df_incid$prs_norm=df_incid$prs_breast_cancer-mean(df_incid$prs_breast_cancer)
summary(df_incid$prs_norm)
summary(df_incid$prs_norm)
summary(mydata$prs_breast_cancer)
# For Fine-Gray subdistribution hazard modeling
# install.packages("cmprsk")  # if not already installed
library(cmprsk)
library(QHScrnomo)
# For data wrangling
library(dplyr)
library(ggplot2)
library(tidyr)
library(riskRegression)
# Use read.table with textConnection to emulate your SAS datalines
mydata <- read.table(
textConnection("
101 01JAN2010 0.45 0.25 1 730 0 .
102 14FEB2011 0.55 0.45 0 . 1 2500
103 30APR2012 0.68 0.52 1 1600 1 2400
104 05MAY2013 0.25 0.10 1 3000 2 .
105 10OCT2014 0.99 0.80 0 . 0 .
106 12DEC2015 0.40 0.20 1 1000 0 .
107 23JUN2016 0.77 0.60 1 2200 1 4000
108 28SEP2017 0.50 0.38 0 . 2 .
109 05JAN2018 0.63 0.42 1 1400 0 .
110 19NOV2019 0.33 0.25 1 3700 1 5500
111 26MAR2020 0.81 0.65 2 430 0 .
112 07JUL2021 0.58 0.40 1 1850 0 .
113 15FEB2022 0.72 0.55 0 . 2 .
114 01MAY2023 0.95 0.78 1 2800 0 .
115 31DEC2024 0.61 0.47 1 360 2 600
"),
header = FALSE,
na.strings = ".",
stringsAsFactors = FALSE
)
# Assign columns
colnames(mydata) <- c("eid", "enrollment_date",
"rorp_prs_norm", "prs_breast_cancer",
"incident_breast_cancer_cr", "time_to_incident_bc_days_cr",
"bc_death_cr", "time_to_bc_death_days_cr")
dim(mydata)
head(mydata, 5)
summary(mydata$prs_breast_cancer)
mydata$prs_norm=mydata$prs_breast_cancer-mean(mydata$prs_breast_cancer)
summary(mydata$prs_norm)
#create variables
mydata <- mydata %>%
mutate(
time_inc   = time_to_incident_bc_days_cr,
status_inc = incident_breast_cancer_cr,
time_mort  = time_to_bc_death_days_cr,
status     = bc_death_cr
)
mydata
# Filter out rows with missing time so crr doesn't break
df_incid <- mydata %>%
filter(!is.na(time_inc) & !is.na(status_inc))
# Fit the Fine-Gray model
# rorp_prs_norm is the only covariate (like your SAS code)
model_incid <- crr(
ftime   = df_incid$time_inc,
fstatus = df_incid$status_inc,
cov1    = matrix(df_incid$rorp_prs_norm,df_incid$prs_norm, ncol=2),
cencode = 0,
failcode = 1
)
# Fit the Fine-Gray model
# rorp_prs_norm is the only covariate (like your SAS code)
model_incid <- crr(
ftime   = df_incid$time_inc,
fstatus = df_incid$status_inc,
cov1    = matrix(c(df_incid$rorp_prs_norm,df_incid$prs_norm), ncol=2),
cencode = 0,
failcode = 1
)
matrix(c(df_incid$rorp_prs_norm,df_incid$prs_norm), ncol=2)
# Fit the Fine-Gray model
# rorp_prs_norm is the only covariate (like your SAS code)
model_incid <- crr(
ftime   = df_incid$time_inc,
fstatus = df_incid$status_inc,
cov1    = matrix(c(df_incid$rorp_prs_norm,df_incid$prs_norm), ncol=2),
cencode = 0,
failcode = 1
)
summary(model_incid)
# Fit the Fine-Gray model
# rorp_prs_norm is the only covariate (like your SAS code)
covariates <- as.matrix(data.frame(df_incid$rorp_prs_norm, df_incid$prs_norm))
model_incid <- crr(
ftime   = df_incid$time_inc,
fstatus = df_incid$status_inc,
cov1    = covariates,
cencode = 0,
failcode = 1
)
summary(model_incid)
model_incid$coef[1]
incid_stderr1_prs <- sqrt(model_incid$var)[2]  # variance -> sqrt for std error
incid_beta1_prs   <- model_incid$coef[2]
incid_stderr1_prs <- sqrt(model_incid$var)[2]  # variance -> sqrt for std error
incid_beta1_prs
incid_stderr1_prs
incid_stderr1 <- sqrt(model_incid$var[1]) # variance -> sqrt for std error
incid_stderr1
incid_beta1_prs   <- model_incid$coef[2]
incid_stderr1_prs <- sqrt(model_incid$var[2])  # variance -> sqrt for std error
incid_beta1_prs
incid_stderr1_prs
model_incid$var[2]
incid_stderr1_prs <- sqrt(model_incid$var[2])  # variance -> sqrt for std error
sqrt(model_incid$se(coef))
model_incid$se
se(coef)
model_incid$se(coef
summary(model_incid)
summary(model_incid)
list(model_incid)
model_incid$se
model_incid$var
sqrt(model_incid$var[1,1])
incid_stderr1_prs <- sqrt(model_incid$var[2,2])  # variance -> sqrt for std error
incid_stderr1_prs
covariates <- as.matrix(data.frame(df_mort$rorp_prs_norm, df_mort$prs_norm))
covariates_mort <- as.matrix(data.frame(df_mort$rorp_prs_norm, df_mort$prs_norm))
model_mort <- crr(
ftime   = df_mort$time_mort,
fstatus = df_mort$status,
cov1    = covariates_mort,
cencode = 0,
failcode = 1
)
covariates_mort <- as.matrix(data.frame(df_mort$rorp_prs_norm, df_mort$prs_norm))
df_mort <- mydata %>%
filter(!is.na(time_mort) & !is.na(status))
covariates_mort <- as.matrix(data.frame(df_mort$rorp_prs_norm, df_mort$prs_norm))
model_mort <- crr(
ftime   = df_mort$time_mort,
fstatus = df_mort$status,
cov1    = covariates_mort,
cencode = 0,
failcode = 1
)
summary(model_mort)
mort_beta1   <- model_mort$coef[1]
mort_stderr1 <- sqrt(model_mort$var[1,1])
mort_beta1
mort_stderr1
mort_beta1_prs   <- model_mort$coef[2]
mort_stderr1_prs <- sqrt(model_mort$var[2,2])
mort_beta1_prs
mort_stderr1_prs
exp(-1.29)/exp(-0.72)
exp(0.57)
exp(-0.57)
exp(0.57)
exp(-0.57)
exp(-0.57)
exp(-1.29)/exp(-0.72)
exp(-0.57)
exp(-1.29)/exp(-0.72)
library(readr)
library(xlsx)
library(openxlsx)
wd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/drive'
icogs_onco_meta <- read.csv("C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/drive/icogs_onco_meta.txt", sep="")
View(icogs_onco_meta)
icogs_onco_meta_rs1800437=icogs_onco_meta[which(grepl('rs1800437',icogs_onco_meta$SNP.iCOGs)),]
icogs_onco_meta_rs1800437
write.xlsx(icogs_onco_meta_rs1800437,file=paste0(wd,'icogs_onco_meta_rs1800437.xlsx'))
which(grepl('rs1800437',icogs_onco_meta$SNP.iCOGs))
vec <- c(1, 0.5, 3, 4, 5)
cummean(vec)
library(dplyr)
cummean(vec)
#j=1
#model=lm
library(keras)
# --- 2) Build the model ---
inp   <- layer_input(shape = p, name = "input")
num_split <- 10
n <-1500
p <- 250
p0 <- 25
q <- 0.1
signal_index <- sample(c(1:p), size = p0, replace = F)
i=10
delta <- i
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
powers=sample(size=p,c(-2:-1,1:2),replace=T)
beta_star <- numeric(p)
beta_star
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- scale(X^2 %*% beta_star + rnorm(n))
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
library(MASS)
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- scale(X^2 %*% beta_star + rnorm(n))
# --- 2) Build the model ---
inp   <- layer_input(shape = p, name = "input")
library(tensorflow)
# --- 2) Build the model ---
inp   <- layer_input(shape = p, name = "input")
library(reticulate)
use_condaenv("r-tensorflow", required = TRUE)
conda_install(
envname  = "r-tensorflow",
packages = c("tensorflow","keras","h5py"),
channel   = "conda-forge",  # often more up‑to‑date builds
pip       = FALSE
)
reticulate::miniconda_remove()
reticulate::miniconda_remove()
library(reticulate)
reticulate::miniconda_remove()
#j=1
library(keras)
library(tensorflow)
library(reticulate)
conda_list()
use_condaenv("tensorF", required = TRUE)
use_condaenv("tensorF", required = TRUE)
#j=1
library(keras)
library(tensorflow)
install.packages("keras3")
install.packages("tensorflow")
install.packages("reticulate")
#j=1
library(keras3)
library(tensorflow)
model <- keras_model_sequential()
#j=1
library(keras)
library(keras3)
#j=1
library(keras3)
library(tensorflow)
model <- keras_model_sequential()
#j=1
reticulate::py_config()
library(reticulate)
use_virtualenv("r-tf-venv", required = TRUE)
use_virtualenv("r-tf", required = TRUE)
use_virtualenv("r-tf", required = TRUE)
library(reticulate)
use_python("C:/…/tf-env/python.exe", required=TRUE)
use_python("C:/…/tf/python.exe", required=TRUE)
use_python("C:/…/tf/python.exe", required=TRUE)
py <- py_discover_config()$python
virtualenv_remove("r-tf-venv", confirm = FALSE)  # clean up any broken one
virtualenv_create("r-tf-venv", python = py)
virtualenv_install("r-tf-venv",
packages = c("tensorflow-cpu>=2.18.0","keras","h5py"))
use_virtualenv("r-tf-venv", required = TRUE)
library(tensorflow)
# install.packages("tensorflow")
tensorflow::install_tensorflow()  # if you haven't yet
library(reticulate)
reticulate::install_python(version = '3.10')
tensorflow::install_tensorflow()
# install.packages("tensorflow")
tensorflow::install_tensorflow()  # if you haven't yet
# install.packages("tensorflow")
tensorflow::install_tensorflow()  # if you haven't yet
library(reticulate)
use_condaenv("r-tf-py310", required = TRUE)
library(reticulate)
use_condaenv("r-tf-py310", required = TRUE)
reticulate::install_miniconda()
reticulate::conda_create("r-tf-py310", python_version = "3.10")
reticulate::use_condaenv("r-tf-py310", required = TRUE)
library(tensorflow)
tensorflow::install_tensorflow(
envname = "r-tf-py310",
version = "2.16.2",
method  = "conda"
)
#j=1
library(keras)
library(tensorflow)
use_virtualenv("r-tf-py310", required = TRUE)
model <- keras_model_sequential() %>%
# 1) square every input feature
layer_lambda(
f         = function(x) k_square(x),
input_shape = p,
name      = "quadratic_layer"
) %>%
# 2) linear regression on the squared features
layer_dense(
units      = 1,
activation = "linear",
name       = "output"
)
use_condaenv("r-tf310", required = TRUE)
library(reticulate)
use_condaenv("r-tf310", required = TRUE)
reticulate::conda_list()
use_condaenv("r-tf-py310", required = TRUE)
### High dimension linear model
rm(list = ls())
mywd='C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
#mywd='C:/Users/mde4023/Documents/GitHub/FDR_Datasplitting'
setwd(mywd)
source('HelperFunctions.R')
#source('TriangleLinRegTrainMS.R')
source(paste0(mywd,'/TriangleBoosterTrainMS.R'))
source(paste0(mywd,'/TriangleRangerTrainMS.R'))
source(paste0(mywd,'/TriangleGBMTrainMS.R'))
source(paste0(mywd,'/Functions Dai/knockoff.R'))
source(paste0(mywd,'/Functions Dai/analysis.R'))
source(paste0(mywd,'/Functions Dai/MBHq.R'))
source(paste0(mywd,'/Functions Dai/DS.R'))
source(paste0(mywd,'/Functions Dai/fdp_power.R'))
#devtools::install_github("Jeremy690/DSfdr/DSfdr",force = TRUE)
library(xgboost)
library(gbm)
library(ranger)
library(MASS)
library(neuralnet)
library(glmnet)
library(knockoff)
library(mvtnorm)
library(hdi)
### algorithmic settings
num_split <- 2
n <-7500
p <- 250
p0 <- 25
q <- 0.1
#set.seed(124)(123) i=5
set.seed(456)
signal_index <- sample(c(1:p), size = p0, replace = F)
#######set up the method for the comparison############# i=10
Compare_SignalStrength <- function(i, s) {
set.seed(s)
delta <- i
# simulate data
X <- mvrnorm(n, mu = rep(0, p), Sigma = diag(p))
beta_star <- numeric(p)
beta_star[signal_index] <- rnorm(p0, 0, delta*sqrt(log(p)/n))*10
y <- scale(X^2 %*% beta_star + rnorm(n))
# run your custom methods
g1 <- ApplyTriangleBoostTrain( X = X, y = y, q = q, num_split = num_split,
signal_index = signal_index, myseed = 1)
# g2 <- ApplyTriangleGBMTrain(   X = X, y = y, q = q, num_split = num_split,
#                                signal_index = signal_index, myseed = 1)
# g3 <- ApplyTriangleRangerTrain(X = X, y = y, q = q, num_split = num_split,
#                               signal_index = signal_index, myseed = 1)
# FDR methods
DS_result      <- DS(          X = X, y = y, q = q, num_split = num_split)
knockoff_result<- knockoff(    X = X, y = y, q = q)
BH_result      <- MBHq(        X = X, y = y, q = q, num_split = num_split)
# init empty results df
ResultsDataFrame <- data.frame(
Method = character(),
Delta  = numeric(),
FDP    = numeric(),
Power  = numeric(),
stringsAsFactors = FALSE
)
# bind all rows
ResultsDataFrame <- rbind(
ResultsDataFrame,
data.frame(Method = "Boost DS",                Delta = i, FDP = g1$DS_fdp,    Power = g1$DS_power),
data.frame(Method = "Boost MS",                Delta = i, FDP = g1$MDS_fdp,   Power = g1$MDS_power),
#data.frame(Method = "GBM DS",                  Delta = i, FDP = g2$DS_fdp,    Power = g2$DS_power),
#data.frame(Method = "GBM MS",                  Delta = i, FDP = g2$MDS_fdp,   Power = g2$MDS_power),
#data.frame(Method = "Ranger DS",               Delta = i, FDP = g3$DS_fdp,    Power = g3$DS_power),
#data.frame(Method = "Ranger MS",               Delta = i, FDP = g3$MDS_fdp,   Power = g3$MDS_power),
data.frame(Method = "DataSplitting",           Delta = i, FDP = DS_result$DS_fdp,  Power = DS_result$DS_power),
data.frame(Method = "MultipleDataSplitting",   Delta = i, FDP = DS_result$MDS_fdp, Power = DS_result$MDS_power),
data.frame(Method = "Knockoff",                Delta = i, FDP = knockoff_result$fdp, Power = knockoff_result$power),
data.frame(Method = "Benjamini–Hochberg (BH)", Delta = i, FDP = BH_result$fdp,     Power = BH_result$power)
)
return(ResultsDataFrame)
}
library(parallel)
mywd <- 'C:/Users/mde4023/OneDrive - Weill Cornell Medicine/0 Projects/FDR_Datasplitting'
setwd(mywd)
# Source helper and method files
source('HelperFunctions.R')
source(file.path(mywd, 'TriangleBoosterTrainMS.R'))
source(file.path(mywd, 'TriangleRangerTrainMS.R'))
source(file.path(mywd, 'TriangleGBMTrainMS.R'))
# Dai’s routines
source(file.path(mywd, 'Functions Dai', 'knockoff.R'))
source(file.path(mywd, 'Functions Dai', 'analysis.R'))
source(file.path(mywd, 'Functions Dai', 'MBHq.R'))
source(file.path(mywd, 'Functions Dai', 'DS.R'))
source(file.path(mywd, 'Functions Dai', 'fdp_power.R'))
# Load required packages
pkgs <- c('xgboost','gbm','ranger','MASS','glmnet','knockoff','mvtnorm','hdi',
'foreach','doParallel')
lapply(pkgs, library, character.only = TRUE)
# === PARAMETER GRID ===
param_grid <- expand.grid(
s = 1:25,
i = seq(from = 7, to = 13, by = 1)
)
# === SET UP PARALLEL BACKEND ===
cl <- makeCluster(detectCores() - 4)
# export working dir so workers can source
clusterExport(cl, 'mywd')
# have each worker source & load libraries
clusterEvalQ(cl, {
setwd(mywd)
source('HelperFunctions.R')
source(file.path(mywd, 'TriangleBoosterTrainMS.R'))
source(file.path(mywd, 'TriangleRangerTrainMS.R'))
source(file.path(mywd, 'TriangleGBMTrainMS.R'))
source(file.path(mywd, 'Functions Dai', 'knockoff.R'))
source(file.path(mywd, 'Functions Dai', 'analysis.R'))
source(file.path(mywd, 'Functions Dai', 'MBHq.R'))
source(file.path(mywd, 'Functions Dai', 'DS.R'))
source(file.path(mywd, 'Functions Dai', 'fdp_power.R'))
lapply(c('xgboost','gbm','ranger','MASS','glmnet','knockoff','mvtnorm','hdi'),
library, character.only = TRUE)
})
registerDoParallel(cl)
# === RUN IN PARALLEL AND WRITE OUT ===
results_list <- foreach(
k = seq_len(nrow(param_grid)),
.packages = pkgs,
.combine  = rbind
) %dopar% {
s_val <- param_grid$s[k]
i_val <- param_grid$i[k]
# compute chunk of results
chunk <- Compare_SignalStrength(i = i_val, s = s_val)
# write out this chunk immediately
fname <- sprintf("Results_s%02d_i%02d.csv", s_val, i_val)
write.csv(chunk, file = fname, row.names = FALSE)
# return for final binding
chunk
}
